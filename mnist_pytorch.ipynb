{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e977f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1ceda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e70df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 1\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "\n",
    "session_inst = aim.Session(experiment='ex2')\n",
    "\n",
    "# aim - Track hyper parameters\n",
    "session_inst.set_params({\n",
    "    'num_epochs': num_epochs,\n",
    "    'num_classes': num_classes,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "}, name='hparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e15b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9234b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f286b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/1875], Loss: 2.3322\n",
      "Epoch [1/1], Step [31/1875], Loss: 0.3120\n",
      "Epoch [1/1], Step [61/1875], Loss: 0.8800\n",
      "Epoch [1/1], Step [91/1875], Loss: 0.3322\n",
      "Epoch [1/1], Step [121/1875], Loss: 0.2209\n",
      "Epoch [1/1], Step [151/1875], Loss: 0.1593\n",
      "Epoch [1/1], Step [181/1875], Loss: 0.1760\n",
      "Epoch [1/1], Step [211/1875], Loss: 0.1401\n",
      "Epoch [1/1], Step [241/1875], Loss: 0.0583\n",
      "Epoch [1/1], Step [271/1875], Loss: 0.2836\n",
      "Epoch [1/1], Step [301/1875], Loss: 0.7866\n",
      "Epoch [1/1], Step [331/1875], Loss: 0.1380\n",
      "Epoch [1/1], Step [361/1875], Loss: 0.1002\n",
      "Epoch [1/1], Step [391/1875], Loss: 0.1707\n",
      "Epoch [1/1], Step [421/1875], Loss: 0.0161\n",
      "Epoch [1/1], Step [451/1875], Loss: 0.0225\n",
      "Epoch [1/1], Step [481/1875], Loss: 0.0454\n",
      "Epoch [1/1], Step [511/1875], Loss: 0.3182\n",
      "Epoch [1/1], Step [541/1875], Loss: 0.1800\n",
      "Epoch [1/1], Step [571/1875], Loss: 0.0638\n",
      "Epoch [1/1], Step [601/1875], Loss: 0.1150\n",
      "Epoch [1/1], Step [631/1875], Loss: 0.0595\n",
      "Epoch [1/1], Step [661/1875], Loss: 0.0065\n",
      "Epoch [1/1], Step [691/1875], Loss: 0.0350\n",
      "Epoch [1/1], Step [721/1875], Loss: 0.0608\n",
      "Epoch [1/1], Step [751/1875], Loss: 0.0479\n",
      "Epoch [1/1], Step [781/1875], Loss: 0.2731\n",
      "Epoch [1/1], Step [811/1875], Loss: 0.0046\n",
      "Epoch [1/1], Step [841/1875], Loss: 0.0431\n",
      "Epoch [1/1], Step [871/1875], Loss: 0.0232\n",
      "Epoch [1/1], Step [901/1875], Loss: 0.0062\n",
      "Epoch [1/1], Step [931/1875], Loss: 0.0050\n",
      "Epoch [1/1], Step [961/1875], Loss: 0.0253\n",
      "Epoch [1/1], Step [991/1875], Loss: 0.0088\n",
      "Epoch [1/1], Step [1021/1875], Loss: 0.0505\n",
      "Epoch [1/1], Step [1051/1875], Loss: 0.0440\n",
      "Epoch [1/1], Step [1081/1875], Loss: 0.0236\n",
      "Epoch [1/1], Step [1111/1875], Loss: 0.0166\n",
      "Epoch [1/1], Step [1141/1875], Loss: 0.1092\n",
      "Epoch [1/1], Step [1171/1875], Loss: 0.2546\n",
      "Epoch [1/1], Step [1201/1875], Loss: 0.0755\n",
      "Epoch [1/1], Step [1231/1875], Loss: 0.2842\n",
      "Epoch [1/1], Step [1261/1875], Loss: 0.1752\n",
      "Epoch [1/1], Step [1291/1875], Loss: 0.4405\n",
      "Epoch [1/1], Step [1321/1875], Loss: 0.0900\n",
      "Epoch [1/1], Step [1351/1875], Loss: 0.0989\n",
      "Epoch [1/1], Step [1381/1875], Loss: 0.0220\n",
      "Epoch [1/1], Step [1411/1875], Loss: 0.0517\n",
      "Epoch [1/1], Step [1441/1875], Loss: 0.5407\n",
      "Epoch [1/1], Step [1471/1875], Loss: 0.0291\n",
      "Epoch [1/1], Step [1501/1875], Loss: 0.0991\n",
      "Epoch [1/1], Step [1531/1875], Loss: 0.0585\n",
      "Epoch [1/1], Step [1561/1875], Loss: 0.0476\n",
      "Epoch [1/1], Step [1591/1875], Loss: 0.0080\n",
      "Epoch [1/1], Step [1621/1875], Loss: 0.0567\n",
      "Epoch [1/1], Step [1651/1875], Loss: 0.0748\n",
      "Epoch [1/1], Step [1681/1875], Loss: 0.0776\n",
      "Epoch [1/1], Step [1711/1875], Loss: 0.0259\n",
      "Epoch [1/1], Step [1741/1875], Loss: 0.0205\n",
      "Epoch [1/1], Step [1771/1875], Loss: 0.0022\n",
      "Epoch [1/1], Step [1801/1875], Loss: 0.0046\n",
      "Epoch [1/1], Step [1831/1875], Loss: 0.0253\n",
      "Epoch [1/1], Step [1861/1875], Loss: 0.0960\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 30 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], '\n",
    "                  'Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1,\n",
    "                                        total_step, loss.item()))\n",
    "\n",
    "            # aim - Track model loss function\n",
    "            aim.track(loss.item(), name='loss', epoch=epoch, subset='train')\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            acc = 100 * correct / total\n",
    "\n",
    "            # aim - Track metrics\n",
    "            aim.track(acc, name='accuracy', epoch=epoch, subset='train')\n",
    "\n",
    "            # TODO: Do actual validation\n",
    "            if i % 300 == 0:\n",
    "                aim.track(loss.item(), name='loss', epoch=epoch, subset='val')\n",
    "                aim.track(acc, name='accuracy', epoch=epoch, subset='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d975b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd20c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "drwxr-xr-x   6 tjain1  ASV\\Domain Users    192 May 18 10:14 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  18 tjain1  ASV\\Domain Users    576 May 17 17:21 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   4 tjain1  ASV\\Domain Users    128 May 18 10:10 \u001b[1m\u001b[36m.aim\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   3 tjain1  ASV\\Domain Users     96 May 18 10:08 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 tjain1  ASV\\Domain Users  13793 May 18 10:14 Untitled.ipynb\r\n",
      "drwxr-xr-x   3 tjain1  ASV\\Domain Users     96 May 18 10:10 \u001b[1m\u001b[36mdata\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f4611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b1259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aim_env] *",
   "language": "python",
   "name": "conda-env-aim_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
